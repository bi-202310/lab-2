# -*- coding: utf-8 -*-
"""regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qrwv72GWwVOQLf8z5CpbT1LLt5pDo2bD

# Laboratorio 2

## 1. Carga de datos
"""

import numpy as np
import pandas as pd

from joblib import dump, load

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import scipy.stats as stats

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 50)

df = pd.read_csv('./data/MotorAlpes_data.csv', index_col=False)
df = df.iloc[:, 1:]

"""## 2. Descripción de los datos"""

df.shape

df.info()
df

df.describe()

"""### 2.1 Completitud"""

df.isnull().sum()

# Show null values as a percentage of the dataframe
df.isnull().sum() / df.shape[0]

"""### 2.2 Consistencia"""

# check if year is between 1994 and 2020

print(all(map(lambda x: x in range(1994,2021), df["year"])))

# check if km_driven is between 1 and 2’360.457

print(all(map(lambda x: x in range(1,2360458), df["km_driven"])))

# check if owner is in ['First Owner', 'Second Owner', 'Third Owner', 'Fourth & Above Owner', 'Test Drive Car']

print(all(map(lambda x: x in ['First Owner', 'Second Owner', 'Third Owner', 'Fourth & Above Owner', 'Test Drive Car'], df["owner"])))

# check if seller_type is in ['Individual', 'Dealer', 'Trustmark Dealer']

print(all(map(lambda x: x in ['Individual', 'Dealer', 'Trustmark Dealer'], df["seller_type"])))

# check if seats is between 2 and 14

print(all(map(lambda x: x in range(2,15), df["seats"])))

# check if fuel is in ['Petrol', 'Diesel', 'CNG', 'LPG', 'Electric']

print(all(map(lambda x: x in ['Petrol', 'Diesel', 'CNG', 'LPG', 'Electric'], df["fuel"])))

# check if transmission is in ['Manual', 'Automatic']

print(all(map(lambda x: x in ['Manual', 'Automatic'], df["transmission"])))

# check if mileage is between 0 and 46.816

print(all(map(lambda x: 34.2 <= x <= 46.816, df["mileage"])))

# check if engine is between 624 and 3604

print(all(map(lambda x: x in range(624,3605), df["engine"])))

# check if max_power is between 34.2 and 400

print(all(map(lambda x: 32.8 <= x <= 400, df["max_power"])))

# check if selling_price is between 363.45 and 121153.38

print(all(map(lambda x: 363.45 <= x <= 121153.38, df["selling_price"])))

"""### 2.3 Consistencia"""

# for every categorical variable, check if there are values that are not in the list of possible values

categorical = ['owner', 'seller_type', 'fuel', 'transmission']

for col in categorical:
    print(col, df[col].unique())

"""## 3. Análisis Exploratorio

### 3.1 Preparación de los datos
"""

# Make a column with the age of the car
df['age'] = 2020 - df['year']

# Fill numerical values with the median so as not to skew the data
df = df.fillna(df.median())

# Fill categorical values with the mode
categorical_cols = ['owner', 'seller_type', 'fuel', 'transmission']
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

# Replace all the categorical values with numbers
df['owner'] = df['owner'].replace({'First Owner': 1, 'Second Owner': 2, 'Third Owner': 3, 'Fourth & Above Owner': 4, 'Test Drive Car': 5})
df['seller_type'] = df['seller_type'].replace({'Individual': 1, 'Dealer': 2, 'Trustmark Dealer': 3})
df['fuel'] = df['fuel'].replace({'Petrol': 1, 'Diesel': 2, 'CNG': 3, 'LPG': 4, 'Electric': 5})
df['transmission'] = df['transmission'].replace({'Manual': 1, 'Automatic': 2})

# Make a scaler to normalize de data
scaler = StandardScaler()
x = scaler.fit_transform(df[features])

# Make a dataframe with the normalized data
df = pd.DataFrame(x, columns=features)

df.info()

# Drop all null values
#df = df.dropna()

# Replace the "year" column values to int
df['year'] = df['year'].astype(int)

"""### 3.2 Visualización de los datos"""

#sns.pairplot(df)
#plt.show()

sns.pairplot(df, x_vars=list(df.columns), y_vars='selling_price', height=4, aspect=1, kind='reg')
sns.pairplot(df, x_vars=list(df.columns), y_vars='selling_price', height=4, aspect=1)

df[df.columns].corr()

# Asumimos que el experto decidio que estos eran los features mas relevantes
features_avec_year = ["year", "km_driven", "seats", "fuel", "transmission", "max_power"]
features = ["km_driven", "seats", "fuel", "transmission", "max_power"]
#TODO: justificar atributos

# Correlation between features chosen
df[features].corr()

"""## 4. Modelamiento"""

x_train, x_test, y_train, y_test = train_test_split(df[features], df['selling_price'], test_size = 0.3, random_state = 1)

x_train

x_test

y_train

y_test

x_train.shape, y_train.shape

x_test.shape, y_test.shape

"""### 4.1. Regresion"""

regression = LinearRegression()

regression.fit(x_train, y_train)

regression.intercept_

pd.DataFrame({'columns': features, 'coef': regression.coef_})

f, axs = plt.subplots(1, len(features), sharey = True, figsize = (20, 4))

for i in range(len(features)):
    col = features[i]
    x = x_train[col]
    m = regression.coef_[i]
    b = regression.intercept_

    axs[i].plot(x, x * m + b)
    axs[i].set_title(col)

# Comparing the real values with the predicted values with an difference percentage for each prediction

y_pred = regression.predict(x_test)

df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
df['Difference'] = df['Actual'] - df['Predicted']
df['Difference %'] = df['Difference'] / df['Actual'] * 100
df

# Print the mean absolute error, mean squared error and the root mean squared error

print('Mean Absolute Error Train:', mean_absolute_error(y_train, regression.predict(x_train)))
print('Mean Absolute Error Test:', mean_absolute_error(y_test, regression.predict(x_test)))

print('Root Mean Squared Error Train:', np.sqrt(mean_squared_error(y_train, regression.predict(x_train))))
print('Root Mean Squared Error Test:', np.sqrt(mean_squared_error(y_test, regression.predict(x_test))))


# Plot real value of objective variable on a boxplot

plt.figure(figsize=(10, 5))
sns.boxplot(y_test, orient='v')
plt.title('Real value of objective variable')
plt.show()

# Plot |real value - predicted value| of objective variable on a boxplot

plt.figure(figsize=(10, 5))
sns.boxplot(abs(y_test - y_pred), orient='v')
plt.title('Absolute error of objective variable')
plt.show()


# Make a pipeline to make the predictions

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('regression', LinearRegression())
])

pipeline.fit(x_train, y_train)

y_pred = pipeline.predict(x_test)
df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

df['Difference'] = df['Actual'] - df['Predicted']
df['Difference %'] = df['Difference'] / df['Actual'] * 100
df

# Print the mean absolute error, mean squared error and the root mean squared error

print('Mean Absolute Error Train:', mean_absolute_error(y_train, pipeline.predict(x_train)))
print('Mean Absolute Error Test:', mean_absolute_error(y_test, pipeline.predict(x_test)))

print('Root Mean Squared Error Train:', np.sqrt(mean_squared_error(y_train, pipeline.predict(x_train))))
print('Root Mean Squared Error Test:', np.sqrt(mean_squared_error(y_test, pipeline.predict(x_test))))

class AntiquityTransformer(BaseEstimator, TransformerMixin):
    def __init__(self):
        pass

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X = X.copy()
        X["year"] = 2020 - X["year"].astype(int)
        return X[["year", "km_driven", "seats", "max_power"]]

numeric_cols = ["year", "km_driven", "seats", "max_power"]
categorical_cols = ["fuel", "transmission"]

numeric_preprocessor = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("antiquity", AntiquityTransformer())
])

categorical_preprocessor = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ('encoder', OneHotEncoder(categories='auto', handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_preprocessor, numeric_cols),
    ('cat', categorical_preprocessor, categorical_cols)
])

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('scaler', StandardScaler()),
    ('regression', LinearRegression())
])